{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following is the first notebook entry as i start to learn machine learning myself\n",
    "#hopefully i can learn to do this and keep up a journal of my progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalar\n",
    "scalar = torch.tensor(7)\n",
    "#scalars are 0 dimensional tensors, they have no shape, no length, no dimension, no size\n",
    "#they are created the same way as tensors, but with a single number, not a list\n",
    "#the dimensions of a tensor a tensor start at 0 and then go to 1, 2, 3, etc \n",
    "#with a one dimensional tensor, you can think of it as a list of numbers like [1, 2, 3, 4, 5]\n",
    "#for example torch.tensor([1, 2, 3, 4, 5]) is a one dimensional tensor with 5 elements\n",
    "#and torch.tensor([1, 2, 3, 4, 5]).shape is torch.Size([5])\n",
    "#whereas torch.tensor(7) is a 0 dimensional tensor with 1 element\n",
    "#and torch.tensor([1],[2]) is a 2 dimensional tensor with 2 elements\n",
    "#and torch.tensor([1],[2]).shape is torch.Size([2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar dimensions:  0\n"
     ]
    }
   ],
   "source": [
    "#to check the dimensions of a tensor (number of rows and columns)\n",
    "scalar.ndim\n",
    "#for clarity\n",
    "print(\"scalar dimensions: \", scalar.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get the number from the tensor\n",
    "scalar.item()\n",
    "#this will convert the value inside of the tensor to a python integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a vector is a single dimensional tensor that can have as many values as you want\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dimensions of the vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tensor is:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#the number of dimensions will match the number of brackets in the array\n",
    "#([]) = 1D array (vector), ([[]]) = 2D array, ([[[ ]]]) = 3D array\n",
    "#the shape of a tensor is how the elements inside the tensor is arranged\n",
    "#this is how you check the shape\n",
    "print(\"The shape of the tensor is: \", vector.shape)\n",
    "#the size([2])means our vector has a shape of [2] this is because of the 2 elements in the vector\n",
    "#([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#this is a matrix\n",
    "matrix = torch.tensor([[7,8],\n",
    "                      [9,10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim\n",
    "#its a 2D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape\n",
    "#the shape is 2 rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#up until now they have all been gone over as tensors\n",
    "#but its really like\n",
    "#0D tensor = scalar, 1D tensor = vector, 2D tensor = matrix\n",
    "#3D tensor = cube of numbers\n",
    "#anything else would be a higher order tensor (4D, 5D, etc)\n",
    "#like a hypercube\n",
    "\n",
    "#this is a tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "TENSOR\n",
    "#tensors can represent almost anything\n",
    "#the above tensor is a representation of sales numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape\n",
    "#this is a bit confusing as it outputs ([1,3,3])\n",
    "#but its a 3 dimenrsional tensor\n",
    "#the dimensions go outter to inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nin conclusion, i have learned about the following:\\nscalar = single number and its dimension is 0\\nvector = a number with dirextion(like wind speed with direction) its dimension is 1\\nmatrix = a 2d array of numbers its dimension is 2\\ntensor = a n-d array of numbers its dimension is n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "in conclusion, i have learned about the following:\n",
    "scalar = single number and its dimension is 0\n",
    "vector = a number with dirextion(like wind speed with direction) its dimension is 1\n",
    "matrix = a 2d array of numbers its dimension is 2\n",
    "tensor = a n-d array of numbers its dimension is n\n",
    "\"\"\"\n",
    "#ive learned i can use docstrings randomly for notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3773, 0.3884, 0.4014, 0.1969],\n",
       "         [0.5108, 0.9586, 0.3679, 0.0583],\n",
       "         [0.2928, 0.8719, 0.9060, 0.2411]]),\n",
       " torch.float32,\n",
       " 2,\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create a tensor of random numbers\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype, random_tensor.ndim, random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([244, 244, 3]), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this can be used to make random tensors in whatever size you want\n",
    "#for example you could use torch.random(244,244,3)\n",
    "#this wuold follow the common shape of an image\n",
    "random_image_size_tensor = torch.rand(size=(244,244,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim\n",
    "#hey copilot do i need to specify the size = key?\n",
    "#copilot: no, you can just do torch.rand((244,244,3))\n",
    "#why the double parenthesis?\n",
    "#copilot: because it's a tuple\n",
    "#so rand takes a tuple as an argument?\n",
    "#copilot: yes\n",
    "#will rand(244,244,3) work?\n",
    "#copilot: no, it will throw an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create a tensor full of zeros\n",
    "zeros = torch.zeros(3,4)\n",
    "zeros, zeros.dtype\n",
    "#this can be used to create a tensor of any shape\n",
    "#and the zeros can be accessed and filled with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create a tensor full of ones\n",
    "ones = torch.ones(3,4)\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to create a range of values\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "#this is the pytorch arange (not arrange) function\n",
    "#it is used to create a range of values with a set interval\n",
    "#the start is the first value in the range\n",
    "#the end is the last value in the range\n",
    "#the step is the interval between each value in the range\n",
    "#its important to remember it returns a tensor\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hey copilot is like everything in torch just about tensors?\n",
    "#copilot: yes, tensors are the main data structure in torch\n",
    "#copilot: tensors are like numpy arrays, but they can also be used on a GPU to accelerate computing\n",
    "#copilot: tensors are also optimized for automatic differentiation\n",
    "#copilot: tensors are also the main data structure for neural networks in pytorch\n",
    "#thanks copilot\n",
    "#copilot: no problem\n",
    "#copilot: I'm here to help\n",
    "#is shape a very important thing in torch?\n",
    "#copilot: yes, shape is very important in torch\n",
    "\"\"\"so in the same way that i would need torch.zeros and torch.ones\n",
    "to create a tensor of zeros and ones of any size from the jump\n",
    "i would need torch.zeros_like and torch.ones_like\n",
    "to create a tensor of ones or zeros in the same shape\n",
    "as some other data im working with?\"\"\"\n",
    "#copilot: yes, that's correct\n",
    "#to create a tensor of zeros or ones in the same shape as some other data\n",
    "ten_zeros = torch.zeros_like(zero_to_ten)\n",
    "ten_zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'), False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copilot why are there so many data types in pytorch?\n",
    "#copilot: because it's a dynamic language\n",
    "#copilot: and it's a language that's designed to be used in a dynamic way\n",
    "#is it bc some of the data types are for the gpu and some are for the cpu\n",
    "#copilot: no, it's because some of the data types are for the gpu and some are for the cpu\n",
    "#that is literally what i asked you\n",
    "#copilot: i'm not sure what you mean by that\n",
    "#-.-\n",
    "#what is the most common data type?\n",
    "#copilot: the most common data type is the float\n",
    "#so like a float32?\n",
    "#copilot: yes\n",
    "#what is the difference between a float and a float32?\n",
    "#copilot: a float is a floating point number, and a float32 is a floating point number with 32 bits\n",
    "#to create a tensor with a specific datatype\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, #the default arg is none, which is automatically a float32\n",
    "                               device=None, #the default arg is none, which is automatically a cpu\n",
    "                               requires_grad=False) #the default arg is false, which means that the tensor will not be used in a gradient computation, if true then operations on the tensor will be recorded\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device, float_32_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) #torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9704, 0.4741, 0.4316, 0.3457],\n",
      "        [0.1010, 0.3938, 0.8459, 0.4510],\n",
      "        [0.5559, 0.8063, 0.6979, 0.7721]])\n",
      "shape of some_tensor: torch.Size([3, 4])\n",
      "dtype of some_tensor: torch.float32\n",
      "device of some_tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f'shape of some_tensor: {some_tensor.shape}')\n",
    "print(f'dtype of some_tensor: {some_tensor.dtype}')\n",
    "print(f'device of some_tensor: {some_tensor.device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([11, 12, 13]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#math works on tensors\n",
    "#to create a tensor and add to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor, tensor + 10\n",
    "#this will add 10 to each element in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to multiply\n",
    "tensor * 10\n",
    "#this will multiply each element by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensors dont change until they have been reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing matrix multplication\n",
    "tensor = torch.tensor([1,2,3]) #one dimensional tensor, or vector wirh a shape of [3]\n",
    "tensor.shape, tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 4, 9]), tensor(14))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"the difference between elemeent wise multiplication\n",
    "and matrix multiplication is the addition of value\n",
    "for tensor i can think about element wise multiplication as\n",
    "[1*1, 2*2, 3*3] = [1,4,9] tensor * tensor\n",
    "and then i can think of a matrix multiplication as [1*1, 2*2, 3*3] = [14]\n",
    "tensor.matmula(tensor)\"\"\"\n",
    "\n",
    "#elementwise, matmulwise\n",
    "tensor * tensor, torch.matmul(tensor, tensor)\n",
    "#this will be useful to quickly do math even graphics like rotating an ascii cube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14), tensor(19))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#its either in python itself or pytorch that the @ \n",
    "#is the symbol for matrix multiplicaion\n",
    "tensor @ tensor, tensor @ torch.tensor([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in the past algo has told me not to waste time with writing my own matrix multiplication functions\n",
    "#this is not to ignore that but to at least know whats under the hood so im not blindly using\n",
    "#by hand implementation\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is obviously much faster\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[39m8\u001b[39m, \u001b[39m11\u001b[39m], \n\u001b[1;32m      8\u001b[0m                          [\u001b[39m9\u001b[39m, \u001b[39m12\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 10\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(tensor_A, tensor_B) \u001b[39m# (this will error)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape\n",
    "\"\"\"\n",
    "this didnt seem obvious to me at first and now i understand\n",
    "what algo and chris meant by touch the tensor and see the shape\n",
    "its becoming clear i coulndt progress without proper pytorch knowlege\n",
    "\n",
    "at first to the eye intuitively these look like something should be able\n",
    "to be done with them and there prolly is but its not what i am trying to\n",
    "do with them right now, the shape is identical, and thats the issue\n",
    "in the case of matrix multiplication the shape has to have the same inner\n",
    "multiplacitively speaking, so [3,2] @ [3,2] wont work but\n",
    "[anything, 2] @ [2, anything] would and if there are errors like this\n",
    "in the future i can just touch the tensor\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear algebra is supposed to be important in machine learning\n",
    "#torch is a library for linear algebra\n",
    "#torch is a library for tensor computation\n",
    "#tensor is a generalization of vectors and matrices\n",
    "\"\"\"a liner linear function can be accurately represented (i think) \n",
    "as y = x * A^T + b\n",
    "where x is the input to the layer,\n",
    "A is the weight matrix, created by the layer, it starts out as random\n",
    "numbers that get adjusted as neural networks lean to better represent\n",
    "patterns in the data\n",
    "T is the transpose of A, because the matrix of weights gets transposed\n",
    "b is the bias vector, created by the layer, it starts out as random\n",
    "y is the output of the layer\n",
    "if this is inaccurate dont sue me im wingin this\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
