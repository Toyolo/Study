{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im going to applu the workflow ive worked on in the other notebook and for simplicity trying the next project standalone so its not a long unusable notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a custom dataset is a collection of data relating to a specific problem, its almost anything i want it to be as long as its organized and prepared correctly. \n",
    "if trying to build a model to classify whether or not a text-based review on a website was positive or negative, the custom dataset might be examples of existing customer reviews and their ratings.\n",
    "Or if trying to build a sound classification app, the custom dataset might be sound samples alongside their sample labels.\n",
    "Or if trying to build a recommendation system for customers purchasing things on our website, the custom dataset might be examples of products other people have bought.\n",
    "pytorch includes functions to load various custom datasets in the torchvision, torchtext, torchaudio, and torchrec libraries.\n",
    "sometimes these will not be enough to do things though, in this case i can subclass torch.utils.data.Dataset and customize it.\n",
    "\n",
    "# im gonna:\n",
    "- apply the workflow ive been practicing for the last few days to a new **computer vision model**\n",
    "    - get data ready\n",
    "    - build or pick model\n",
    "    - fit model to data \n",
    "    - make prediction\n",
    "    - evaluate\n",
    "    - improve\n",
    "    - save\n",
    "    - load\n",
    "- instead of using a built in pytorch toy dataset i will be using a dataset consisting of images of pizza, steak, or sushi\n",
    "- get data\n",
    "- prep data\n",
    "- transform data\n",
    "- load data\n",
    "- load custom dataset\n",
    "- other transformations\n",
    "- model\n",
    "- explore loss curves\n",
    "- augment model\n",
    "- compare results\n",
    "- make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first thing i need is the data im going to use a subset of the food101 dataset, food101 is popular computer vision benchmark and it contains 1000 images of 101 different kinds of foods, totaling 101,000 images (75,750 train and 25,250 test). its also preformatted for what i wanna use it for but i will learn to format as i go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "#setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "#if the image folder doesn't exist, download it and prep it\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    #download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    #unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that the data has been downloaded and managed nicely (if youre better at management of data and stuff this is prolly not nicely done but i am not so it is to me)\n",
    "i need to prepare the data, and get really comfortable with looking at it altering it and using it.\n",
    "# data preperation seems to be one of if not the biggest and most important parts of machine learning and data science. \n",
    "before starting any project i should know what data im working with and in this case its litterally images of pizza steal and sushi in standard image classification format. image classification format contains seperate classes of images in seperate directories titled with a particular class name. all images of pizza are contained in the pizza/ directory. this format seems to be pretty popular in different image classifier benchmarks\n",
    "```pizza_steak_sushi/ <- overall dataset folder\n",
    "    train/ <- training images\n",
    "        pizza/ <- class name as folder name\n",
    "            image01.jpeg\n",
    "            image02.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image24.jpeg\n",
    "            image25.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image37.jpeg\n",
    "            ...\n",
    "    test/ <- testing images\n",
    "        pizza/\n",
    "            image101.jpeg\n",
    "            image102.jpeg\n",
    "            ...\n",
    "        steak/\n",
    "            image154.jpeg\n",
    "            image155.jpeg\n",
    "            ...\n",
    "        sushi/\n",
    "            image167.jpeg\n",
    "            ...```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
